{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Libraries \ud83d\udcda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load data \ud83d\udce5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diagnoses_df = pd.read_csv(\"data/ground_truth_df.csv\")\n",
        "diagnoses_df['Codigos_diagnosticos'] = diagnoses_df['Codigos_diagnosticos'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
        "diagnoses_df['Diagnosticos_estandar'] = diagnoses_df['Diagnosticos_estandar'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
        "diagnoses_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Models using embeddings as input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "EMB_PATH = \"X_embeddings.npy\"\n",
        "\n",
        "if os.path.isfile(EMB_PATH):\n",
        "    X_embeddings = np.load(EMB_PATH)\n",
        "else:\n",
        "    embeddings_model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
        "    texts = [\"query: \" + t for t in diagnoses_df['Descripcion_diagnosticos']]\n",
        "    X_embeddings = embeddings_model.encode(texts, convert_to_tensor=False, show_progress_bar=True)\n",
        "    np.save(EMB_PATH, X_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(diagnoses_df['Diagnosticos_estandar'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "val_size, test_size = 0.15, 0.15\n",
        "\n",
        "X_temp, X_test, Y_temp, Y_test = train_test_split(X_embeddings, y, test_size=test_size, random_state=42)\n",
        "\n",
        "# Then split train+val into train and val\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=val_size/(1-test_size), random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "def evaluate(model, X, Y_true, label=\"\"):\n",
        "    Y_pred = model.predict(X)\n",
        "    print(f\"\\n=== Evaluation on {label} set ===\")\n",
        "    print(f\"F1 score (micro):  {f1_score(Y_true, Y_pred, average='micro', zero_division=0):.4f}\", )\n",
        "    print(f\"Precision (micro): {precision_score(Y_true, Y_pred, average='micro', zero_division=0):.4f}\", )\n",
        "    print(f\"Recall (micro):    {recall_score(Y_true, Y_pred, average='micro', zero_division=0):.4f}\", )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1. XGBoost per diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.base import clone\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "class CustomOvR_XGBoost:\n",
        "    def __init__(self, base_model=None):\n",
        "        default_params = dict(\n",
        "             # Hyper-parameters\n",
        "            n_estimators       = 300,\n",
        "            learning_rate      = 0.1,\n",
        "            max_depth          = 8,\n",
        "            subsample          = 0.8,\n",
        "            colsample_bytree   = 0.8,\n",
        "\n",
        "            # Fixed settings for multilabel on GPU\n",
        "            objective          = \"binary:logistic\",\n",
        "            eval_metric        = \"logloss\",\n",
        "            tree_method        = \"hist\",\n",
        "            device             = \"cuda\",\n",
        "            n_jobs             = -1,\n",
        "            random_state       = 42,\n",
        "            verbosity          = 1\n",
        "        )\n",
        "        self.base_model = clone(base_model) if base_model else XGBClassifier(**default_params)\n",
        "        self.models = []\n",
        "        self._constant_targets = []  # guarda clases vac\u00edas/constantes\n",
        "\n",
        "    # -------- entrenamiento --------\n",
        "    def fit(self, X, Y, eval_set=None, verbose=False):\n",
        "        self.models.clear()\n",
        "        self._constant_targets.clear()\n",
        "\n",
        "        for k in tqdm(range(Y.shape[1]), desc=\"Training XGBoost classifiers\"):\n",
        "            yk = Y[:, k]\n",
        "\n",
        "            # \u00bfLa columna est\u00e1 vac\u00eda o es constante?\n",
        "            if np.all(yk == 0) or np.all(yk == 1):\n",
        "                self.models.append(None)          # marcador\n",
        "                self._constant_targets.append(int(yk[0]))\n",
        "                continue\n",
        "\n",
        "            model = clone(self.base_model)\n",
        "            if eval_set is not None:\n",
        "                eval_set_k = [(eval_X, eval_y[:, k]) for eval_X, eval_y in eval_set]\n",
        "                model.fit(X, yk, eval_set=eval_set_k, verbose=verbose)\n",
        "            else:\n",
        "                model.fit(X, yk)\n",
        "            self.models.append(model)\n",
        "            self._constant_targets.append(None)\n",
        "\n",
        "        return self\n",
        "\n",
        "    # -------- predicci\u00f3n --------\n",
        "    def predict(self, X):\n",
        "        out = np.zeros((X.shape[0], len(self.models)), dtype=np.int8)\n",
        "\n",
        "        for k, model in enumerate(self.models):\n",
        "            if model is None:                 # etiqueta vac\u00eda/constante\n",
        "                out[:, k] = self._constant_targets[k]\n",
        "            else:\n",
        "                # Umbral 0.5 sobre la probabilidad positiva\n",
        "                out[:, k] = (model.predict_proba(X)[:, 1] > 0.5).astype(np.int8)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2.1. Baseline XGBoost per diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Baseline Embeddings to xgboost per diagnosis\n",
        "clf = CustomOvR_XGBoost()\n",
        "clf.fit(X_train, Y_train, eval_set=[(X_val, Y_val)], verbose=False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(clf, X_train, Y_train, label=\"Train\")\n",
        "evaluate(clf, X_val, Y_val, label=\"Validation\")\n",
        "evaluate(clf, X_test, Y_test, label=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(clf, \"models/baseline_xgboost_per_diagnosis.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2.2. Optuna XGBoost per diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# --- Optuna objective --------------------------------------------------------\n",
        "def objective(trial):\n",
        "    \"\"\"Optuna objective function that trains an XGBClassifier and returns F1_micro.\"\"\"\n",
        "    \n",
        "    # Hyper-parameter search space\n",
        "    params = {\n",
        "        \"n_estimators\":      trial.suggest_int(\"n_estimators\", 100, 800),\n",
        "        \"learning_rate\":     trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
        "        \"max_depth\":         trial.suggest_int(\"max_depth\", 3, 12),\n",
        "        \"subsample\":         trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\":  trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "        \"gamma\":             trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
        "        \"min_child_weight\":  trial.suggest_int(\"min_child_weight\", 1, 10),\n",
        "        \"reg_alpha\":         trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
        "        \"reg_lambda\":        trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
        "\n",
        "        # Fixed settings for multilabel on GPU\n",
        "        \"objective\":    \"binary:logistic\",\n",
        "        \"eval_metric\":  \"logloss\",\n",
        "        \"tree_method\":  \"hist\",\n",
        "        \"device\":       \"cuda\",\n",
        "        \"n_jobs\":       -1,\n",
        "        \"random_state\": 42,\n",
        "        \"verbosity\":    1,\n",
        "    }\n",
        "\n",
        "    print(\n",
        "        f\"\ud83d\udd0d Trial {trial.number} | \"\n",
        "        f\"n_estimators={params['n_estimators']}, \"\n",
        "        f\"learning_rate={params['learning_rate']:.5f}, \"\n",
        "        f\"max_depth={params['max_depth']}, \"\n",
        "        f\"subsample={params['subsample']:.3f}, \"\n",
        "        f\"colsample_bytree={params['colsample_bytree']:.3f}, \"\n",
        "        f\"gamma={params['gamma']:.3f}, \"\n",
        "        f\"min_child_weight={params['min_child_weight']}, \"\n",
        "        f\"reg_alpha={params['reg_alpha']:.3f}, \"\n",
        "        f\"reg_lambda={params['reg_lambda']:.3f}\"\n",
        "    )\n",
        "\n",
        "    # Model training\n",
        "    base_model = XGBClassifier(**params)\n",
        "    model = CustomOvR_XGBoost(base_model=base_model)\n",
        "    model.fit(\n",
        "        X_train, Y_train,\n",
        "        eval_set=[(X_val, Y_val)],\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # Validation metric\n",
        "    y_pred = model.predict(X_val)\n",
        "    f1_micro = f1_score(Y_val, y_pred, average=\"micro\", zero_division=0)\n",
        "\n",
        "    # Optuna minimises the returned value\n",
        "    return f1_micro\n",
        "\n",
        "study = optuna.create_study(\n",
        "    study_name=\"multilabel_xgboost\",\n",
        "    direction=\"maximize\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5),\n",
        "    storage=\"sqlite:///optuna/XGBoost_per_diagnosis.db\",\n",
        "    load_if_exists=True\n",
        ")\n",
        "\n",
        "TOTAL_TRIALS = 50\n",
        "remaining_trials = max(TOTAL_TRIALS - len(study.trials), 0)\n",
        "study.optimize(objective, n_trials=remaining_trials, n_jobs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\u2705 Best trial:\", study.best_trial.number)\n",
        "print(\"\ud83c\udfc6 Best configuration:\", study.best_params)\n",
        "print(\"\ud83d\udd1d Best F1 val:\", study.best_value)\n",
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train\n",
        "params = {\n",
        "    \"n_estimators\":      study.best_params['n_estimators'],\n",
        "    \"learning_rate\":     study.best_params['learning_rate'],\n",
        "    \"max_depth\":         study.best_params['max_depth'],\n",
        "    \"subsample\":         study.best_params['subsample'],\n",
        "    \"colsample_bytree\":  study.best_params['colsample_bytree'],\n",
        "    \"gamma\":             study.best_params['gamma'],\n",
        "    \"min_child_weight\":  study.best_params['min_child_weight'],\n",
        "    \"reg_alpha\":         study.best_params['reg_alpha'],\n",
        "    \"reg_lambda\":        study.best_params['reg_lambda'],\n",
        "    # Fixed settings for multilabel on GPU\n",
        "    \"objective\":    \"binary:logistic\",\n",
        "    \"eval_metric\":  \"logloss\",\n",
        "    \"tree_method\":  \"hist\",\n",
        "    \"device\":       \"cuda\",\n",
        "    \"n_jobs\":       -1,\n",
        "    \"random_state\": 42,\n",
        "    \"verbosity\":    1,\n",
        "}\n",
        "base_model = XGBClassifier(**params)\n",
        "clf = CustomOvR_XGBoost(base_model=base_model)\n",
        "clf.fit(X_train, Y_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(clf, X_train, Y_train, label=\"Train\")\n",
        "evaluate(clf, X_val, Y_val, label=\"Validation\")\n",
        "evaluate(clf, X_test, Y_test, label=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(clf, \"models/optimized_xgboost_per_diagnosis.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. Multilabel XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2.1. Baseline Multilabel XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Baseline Embeddings to multilabel xgboost\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "clf = XGBClassifier(\n",
        "    # Hyper-parameters\n",
        "    n_estimators       = 300,\n",
        "    learning_rate      = 0.1,\n",
        "    max_depth          = 8,\n",
        "    subsample          = 0.8,\n",
        "    colsample_bytree   = 0.8,\n",
        "\n",
        "    # Fixed settings for multilabel on GPU\n",
        "    objective          = \"binary:logistic\",\n",
        "    eval_metric        = \"logloss\",\n",
        "    tree_method        = \"hist\",\n",
        "    device             = \"cuda\",\n",
        "    n_jobs             = -1,\n",
        "    random_state       = 42,\n",
        "    verbosity          = 1\n",
        ")\n",
        "\n",
        "clf.fit(X_train, Y_train, verbose=False, eval_set=[(X_val, Y_val)])#4.22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(clf, X_train, Y_train, label=\"Train\")\n",
        "evaluate(clf, X_val, Y_val, label=\"Validation\")\n",
        "evaluate(clf, X_test, Y_test, label=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(clf, \"models/baseline_xgboost_multilabel.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2.2. Optuna XGBoost multilabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# --- Optuna objective --------------------------------------------------------\n",
        "def objective(trial):\n",
        "    \"\"\"Optuna objective function that trains an XGBClassifier and returns F1_micro.\"\"\"\n",
        "    \n",
        "    # Hyper-parameter search space\n",
        "    params = {\n",
        "        \"n_estimators\":      trial.suggest_int(\"n_estimators\", 100, 800),\n",
        "        \"learning_rate\":     trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
        "        \"max_depth\":         trial.suggest_int(\"max_depth\", 3, 12),\n",
        "        \"subsample\":         trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\":  trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "        \"gamma\":             trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
        "        \"min_child_weight\":  trial.suggest_int(\"min_child_weight\", 1, 10),\n",
        "        \"reg_alpha\":         trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
        "        \"reg_lambda\":        trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
        "\n",
        "        # Fixed settings for multilabel on GPU\n",
        "        \"objective\":    \"binary:logistic\",\n",
        "        \"eval_metric\":  \"logloss\",\n",
        "        \"tree_method\":  \"hist\",\n",
        "        \"device\":       \"cuda\",\n",
        "        \"n_jobs\":       -1,\n",
        "        \"random_state\": 42,\n",
        "        \"verbosity\":    1,\n",
        "    }\n",
        "\n",
        "    print(\n",
        "        f\"\ud83d\udd0d Trial {trial.number} | \"\n",
        "        f\"n_estimators={params['n_estimators']}, \"\n",
        "        f\"learning_rate={params['learning_rate']:.5f}, \"\n",
        "        f\"max_depth={params['max_depth']}, \"\n",
        "        f\"subsample={params['subsample']:.3f}, \"\n",
        "        f\"colsample_bytree={params['colsample_bytree']:.3f}, \"\n",
        "        f\"gamma={params['gamma']:.3f}, \"\n",
        "        f\"min_child_weight={params['min_child_weight']}, \"\n",
        "        f\"reg_alpha={params['reg_alpha']:.3f}, \"\n",
        "        f\"reg_lambda={params['reg_lambda']:.3f}\"\n",
        "    )\n",
        "\n",
        "    # Model training\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(\n",
        "        X_train, Y_train,\n",
        "        eval_set=[(X_val, Y_val)],\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # Validation metric\n",
        "    y_pred = model.predict(X_val)\n",
        "    f1_micro = f1_score(Y_val, y_pred, average=\"micro\", zero_division=0)\n",
        "\n",
        "    # Optuna minimises the returned value\n",
        "    return f1_micro\n",
        "\n",
        "study = optuna.create_study(\n",
        "    study_name=\"multilabel_xgboost\",\n",
        "    direction=\"maximize\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5),\n",
        "    storage=\"sqlite:///optuna/XGBoost_multilabel.db\",\n",
        "    load_if_exists=True\n",
        ")\n",
        "\n",
        "TOTAL_TRIALS = 50\n",
        "remaining_trials = max(TOTAL_TRIALS - len(study.trials), 0)\n",
        "study.optimize(objective, n_trials=remaining_trials, n_jobs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\u2705 Best trial:\", study.best_trial.number)\n",
        "print(\"\ud83c\udfc6 Best configuration:\", study.best_params)\n",
        "print(\"\ud83d\udd1d Best F1 val:\", study.best_value)\n",
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "clf = XGBClassifier(\n",
        "    # Hyper-parameters\n",
        "    n_estimators       = study.best_params['n_estimators'],\n",
        "    learning_rate      = study.best_params['learning_rate'],\n",
        "    max_depth          = study.best_params['max_depth'],\n",
        "    subsample          = study.best_params['subsample'],\n",
        "    colsample_bytree   = study.best_params['colsample_bytree'],\n",
        "    gamma              = study.best_params['gamma'],\n",
        "    min_child_weight   = study.best_params['min_child_weight'],\n",
        "    reg_alpha          = study.best_params['reg_alpha'],\n",
        "    reg_lambda         = study.best_params['reg_lambda'],\n",
        "\n",
        "\n",
        "    # Fixed settings for multilabel on GPU\n",
        "    objective          = \"binary:logistic\",\n",
        "    eval_metric        = \"logloss\",\n",
        "    tree_method        = \"hist\",\n",
        "    device             = \"cuda\",\n",
        "    n_jobs             = -1,\n",
        "    random_state       = 42,\n",
        "    verbosity          = 1\n",
        ")\n",
        "\n",
        "clf.fit(X_train, Y_train, verbose=False, eval_set=[(X_val, Y_val)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(clf, X_train, Y_train, label=\"Train\")\n",
        "evaluate(clf, X_val, Y_val, label=\"Validation\")\n",
        "evaluate(clf, X_test, Y_test, label=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(clf, \"models/optimized_xgboost_multilabel.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3. Random Forest per diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Baseline Embeddings to random forest per diagnosis\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.base import clone\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "class CustomOvR_RandomForest:\n",
        "    def __init__(self, base_model=None):\n",
        "        if base_model is None:\n",
        "            self.base_model = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "        else:\n",
        "            self.base_model = base_model\n",
        "        self.models = []\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        self.models = []\n",
        "        for i in tqdm(range(Y.shape[1]), desc=\"Training RF classifiers\"):\n",
        "            model = clone(self.base_model)\n",
        "            model.fit(X, Y[:, i])\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = [model.predict(X) for model in self.models]\n",
        "        return np.array(preds).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.3.1. Baseline Random Forest per diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train\n",
        "clf = CustomOvR_RandomForest(RandomForestClassifier(n_estimators=25, n_jobs=-1, random_state=42))\n",
        "clf.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(clf, X_train, Y_train, label=\"Train\")\n",
        "evaluate(clf, X_val, Y_val, label=\"Validation\")\n",
        "evaluate(clf, X_test, Y_test, label=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(clf, \"models/baseline_random_forest_per_diagnosis.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.3.2. Optuna Random Forest per diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------------------- Imports ----------------------------------------\n",
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Aseg\u00farate de tener en el mismo entorno tu clase:\n",
        "# from mymodule import CustomOvR_RandomForest\n",
        "\n",
        "# ------------------------- Optuna objective ----------------------------------\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Optuna objective function that tunes a RandomForest inside\n",
        "    a CustomOvR_RandomForest wrapper and returns the micro-averaged\n",
        "    F1 score on a validation set.\n",
        "    \"\"\"\n",
        "\n",
        "    # -------------------- Hyper-parameter search space -----------------------\n",
        "    rf_params = {\n",
        "        \"n_estimators\":      trial.suggest_int(\"n_estimators\", 5, 50),\n",
        "        \"max_depth\":         trial.suggest_int(\"max_depth\", 5, 25),\n",
        "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 6),\n",
        "        \"min_samples_leaf\":  trial.suggest_int(\"min_samples_leaf\", 1, 4),\n",
        "        \"max_features\":      trial.suggest_categorical(\n",
        "                                \"max_features\", [\"sqrt\", \"log2\", None]\n",
        "                             ),\n",
        "        \"bootstrap\":         trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
        "        \"class_weight\":      trial.suggest_categorical(\n",
        "                                \"class_weight\", [None, \"balanced\"]\n",
        "                             ),\n",
        "\n",
        "        # Fixed settings\n",
        "        \"n_jobs\":       -1,     # use all CPU cores\n",
        "        \"random_state\": 42,\n",
        "        \"verbose\":      0,\n",
        "    }\n",
        "\n",
        "    # Pretty print of the current trial\u2019s hyper-parameters\n",
        "    print(\n",
        "        f\"\ud83d\udd0d Trial {trial.number:02d} | \"\n",
        "        f\"n_estimators={rf_params['n_estimators']}, \"\n",
        "        f\"max_depth={rf_params['max_depth']}, \"\n",
        "        f\"min_samples_split={rf_params['min_samples_split']}, \"\n",
        "        f\"min_samples_leaf={rf_params['min_samples_leaf']}, \"\n",
        "        f\"max_features={rf_params['max_features']}, \"\n",
        "        f\"bootstrap={rf_params['bootstrap']}, \"\n",
        "        f\"class_weight={rf_params['class_weight']}\"\n",
        "    )\n",
        "\n",
        "    # ------------------------- Model training --------------------------------\n",
        "    base_rf = RandomForestClassifier(**rf_params)\n",
        "    model = CustomOvR_RandomForest(base_model=base_rf)\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    # ----------------------- Validation metric -------------------------------\n",
        "    y_pred = model.predict(X_val)\n",
        "    f1_micro = f1_score(Y_val, y_pred, average=\"micro\", zero_division=0)\n",
        "\n",
        "    # Optuna maximises when direction=\"maximize\"\n",
        "    return f1_micro\n",
        "\n",
        "\n",
        "# ----------------------------- Optuna study ----------------------------------\n",
        "study = optuna.create_study(\n",
        "    study_name=\"Multimodel_random_forest\",\n",
        "    direction=\"maximize\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5),\n",
        "    storage=\"sqlite:///optuna/RandomForest_per_diagnosis.db\",\n",
        "    load_if_exists=True\n",
        ")\n",
        "\n",
        "# ------------------------ Launch the optimization ----------------------------\n",
        "TOTAL_TRIALS = 25           # ajusta si necesitas m\u00e1s/menos exploraci\u00f3n\n",
        "remaining_trials = max(TOTAL_TRIALS - len(study.trials), 0)\n",
        "study.optimize(objective, n_trials=remaining_trials, n_jobs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\u2705 Best trial:\", study.best_trial.number)\n",
        "print(\"\ud83c\udfc6 Best configuration:\", study.best_params)\n",
        "print(\"\ud83d\udd1d Best F1 val:\", study.best_value)\n",
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Baseline Embeddings to random forest per diagnosis\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.base import clone\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\":      study.best_params['n_estimators'],\n",
        "    \"max_depth\":         study.best_params['max_depth'],\n",
        "    \"min_samples_split\": study.best_params['min_samples_split'],\n",
        "    \"min_samples_leaf\":  study.best_params['min_samples_leaf'],\n",
        "    \"max_features\":      study.best_params['max_features'],\n",
        "    \"bootstrap\":         study.best_params['bootstrap'],\n",
        "    \"class_weight\":      study.best_params['class_weight'],\n",
        "\n",
        "    # Fixed settings\n",
        "    \"n_jobs\":       -1,     # use all CPU cores\n",
        "    \"random_state\": 42,\n",
        "    \"verbose\":      0,\n",
        "}\n",
        "\n",
        "# Train\n",
        "base_rf = RandomForestClassifier(**params)\n",
        "clf = CustomOvR_RandomForest(base_model=base_rf)\n",
        "clf.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(clf, X_train, Y_train, label=\"Train\")\n",
        "evaluate(clf, X_val, Y_val, label=\"Validation\")\n",
        "evaluate(clf, X_test, Y_test, label=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(clf, \"models/optimized_random_forest_per_diagnosis.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4. Multilabel Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.4.1. Baseline Multilabel Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Baseline Embeddings to multilabel random forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report  # opcional\n",
        "\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    n_jobs=-1,        # usa todos los n\u00facleos de la CPU\n",
        "    random_state=42,   # para reproducibilidad\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 2. Entrenar\n",
        "clf.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(clf, X_train, Y_train, label=\"Train\")\n",
        "evaluate(clf, X_val, Y_val, label=\"Validation\")\n",
        "evaluate(clf, X_test, Y_test, label=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(clf, \"models/baseline_random_forest_multilabel.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.4.2. Optuna Random Forest multilabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------------------------- Imports ---------------------------------------\n",
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# --------------------------- Optuna objective --------------------------------\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Optuna objective function that trains a RandomForestClassifier and\n",
        "    returns the micro-averaged F1 score on a validation set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Hyper-parameter search space\n",
        "    params = {\n",
        "        # Hyper-parameters (reduced search space)\n",
        "        \"n_estimators\":      trial.suggest_int(\"n_estimators\", 50, 150),\n",
        "        \"max_depth\":         trial.suggest_int(\"max_depth\", 5, 20),\n",
        "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 4),\n",
        "        \"min_samples_leaf\":  trial.suggest_int(\"min_samples_leaf\", 1, 4),\n",
        "        \"max_features\":      trial.suggest_categorical(\n",
        "                                \"max_features\", [\"sqrt\", \"log2\"]\n",
        "                             ),\n",
        "        \"bootstrap\":         trial.suggest_categorical(\"bootstrap\", [True]),\n",
        "        \"class_weight\":      trial.suggest_categorical(\n",
        "                                \"class_weight\", [None, \"balanced\"]\n",
        "                             ),\n",
        "\n",
        "        # Fixed settings\n",
        "        \"n_jobs\":      -1,   # use all CPU cores\n",
        "        \"random_state\": 42,\n",
        "        \"verbose\":      0,\n",
        "    }\n",
        "\n",
        "    # Pretty print of the current trial\u2019s hyper-parameters\n",
        "    print(\n",
        "        f\"\ud83d\udd0d Trial {trial.number:02d} | \"\n",
        "        f\"n_estimators={params['n_estimators']}, \"\n",
        "        f\"max_depth={params['max_depth']}, \"\n",
        "        f\"min_samples_split={params['min_samples_split']}, \"\n",
        "        f\"min_samples_leaf={params['min_samples_leaf']}, \"\n",
        "        f\"max_features={params['max_features']}, \"\n",
        "        f\"bootstrap={params['bootstrap']}, \"\n",
        "        f\"class_weight={params['class_weight']}\"\n",
        "    )\n",
        "\n",
        "    # ------------------------- Model training --------------------------------\n",
        "    model = RandomForestClassifier(**params)\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    # ----------------------- Validation metric --------------------------------\n",
        "    y_pred = model.predict(X_val)\n",
        "    f1_micro = f1_score(Y_val, y_pred, average=\"micro\", zero_division=0)\n",
        "\n",
        "    # Optuna maximiza cuando direction=\"maximize\"\n",
        "    return f1_micro\n",
        "\n",
        "\n",
        "# ---------------------------- Optuna study -----------------------------------\n",
        "study = optuna.create_study(\n",
        "    study_name=\"multilabel_random_forest\",\n",
        "    direction=\"maximize\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5),\n",
        "    storage=\"sqlite:///optuna/RandomForest_multilabel.db\",\n",
        "    load_if_exists=True\n",
        ")\n",
        "\n",
        "# ----------------------- Launch the optimization -----------------------------\n",
        "TOTAL_TRIALS = 50\n",
        "remaining_trials = max(TOTAL_TRIALS - len(study.trials), 0)\n",
        "study.optimize(objective, n_trials=remaining_trials, n_jobs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\u2705 Best trial:\", study.best_trial.number)\n",
        "print(\"\ud83c\udfc6 Best configuration:\", study.best_params)\n",
        "print(\"\ud83d\udd1d Best F1 val:\", study.best_value)\n",
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Baseline Embeddings to multilabel random forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report  # opcional\n",
        "\n",
        "\n",
        "params = {\n",
        "    # Hyper-parameters\n",
        "    \"n_estimators\":      study.best_params['n_estimators'],\n",
        "    \"max_depth\":         study.best_params['max_depth'],\n",
        "    \"min_samples_split\": study.best_params['min_samples_split'],\n",
        "    \"min_samples_leaf\":  study.best_params['min_samples_leaf'],\n",
        "    \"max_features\":      study.best_params['max_features'],\n",
        "    \"bootstrap\":         study.best_params['bootstrap'],\n",
        "    \"class_weight\":      study.best_params['class_weight'],\n",
        "\n",
        "    # Fixed settings\n",
        "    \"n_jobs\":      -1,   # use all CPU cores\n",
        "    \"random_state\": 42,\n",
        "    \"verbose\":      0,\n",
        "}\n",
        "clf = RandomForestClassifier(**params)\n",
        "\n",
        "# 2. Entrenar\n",
        "clf.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(clf, X_train, Y_train, label=\"Train\")\n",
        "evaluate(clf, X_val, Y_val, label=\"Validation\")\n",
        "evaluate(clf, X_test, Y_test, label=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(clf, \"models/optimized_random_forest_multilabel.pkl\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
